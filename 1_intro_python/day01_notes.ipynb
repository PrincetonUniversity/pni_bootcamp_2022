{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8f8a97",
   "metadata": {},
   "source": [
    "# Python Day 2 \n",
    "\n",
    "## Goals for Today\n",
    "\n",
    "There are three main goals for today's lecture:\n",
    "\n",
    "1. Getting comfortable with making, manipulating, and visualizing NumPy arrays and Pandas data frames.\n",
    "    - Basic linear algebra operations\n",
    "2. Building the habit of searching for and reading [code documentation](https://numpy.org/doc/stable/reference/).\n",
    "3. Breaking down complex programming challenges step-by-step and using pseudo-code.\n",
    "    - Clean data\n",
    "    - Characterize data\n",
    "    - Plot result\n",
    "    - Test significance of result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d595b",
   "metadata": {},
   "source": [
    "## Section 1: Importing Libraries\n",
    "If vanilla python seems rather lackluster, that's because it is. Fortunately, the python scientific stack adds a broad and powerful array of python packages to fill in the gaps. Once installed, python packages are easily loaded in for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ab300",
   "metadata": {},
   "source": [
    "Commands from packages are like attributes of objects. Many libraries also have submodules, or clusters of related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6115b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg\n",
    "np.random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b722f0b",
   "metadata": {},
   "source": [
    "## Section 2: NumPy Array Basics\n",
    "\n",
    "NumPy arrays have many built-in attributes that make them very convenient to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "## Generate arbitrary array.\n",
    "x = np.random.randint(0,9,(3,3,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d50c8",
   "metadata": {},
   "source": [
    "With ipython environments, if you cannot remember the functions available you can make use of **tab-complete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e81e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try out tab-complete.\n",
    "x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095b48d",
   "metadata": {},
   "source": [
    "The following attributes help you keep track of the most important pieces of metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cac53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)    # shape: dimensions of array\n",
    "print(x.ndim)     # ndim:  number of dimensions of array\n",
    "print(x.size)     # size:  number of elements in array\n",
    "print(x.dtype)    # dtype: data type of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4a200",
   "metadata": {},
   "source": [
    "Changing the dtype of an array is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60452220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.astype(int);         # change to int\n",
    "x.astype(str);         # change to string\n",
    "x.astype(float);       # change to float (default)\n",
    "x.astype(np.float16);  # change to float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb015a",
   "metadata": {},
   "source": [
    "Many useful functions are built-in to NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94fc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min:', x.min())      # Get max of array.\n",
    "print('Max:', x.max())      # Get min of array.\n",
    "print('Sum:', x.sum())      # Get sum of array.\n",
    "print('Mean:',x.mean())     # Get mean of array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbc461",
   "metadata": {},
   "source": [
    "One of the most crucial functions is `copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be655e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.copy()\n",
    "x[:] = 0\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf63f64",
   "metadata": {},
   "source": [
    "### Mini-exercise\n",
    "\n",
    "a) Look up `np.linspace`. How does it differ from `np.arange`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,10,2),np.linspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,10,2),np.linspace(0,1,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9ff41",
   "metadata": {},
   "source": [
    "b) Using `np.linspace`, make an evenly-spaced array, 21 elements long, spanning from -1 to 1. Confirm it's length = 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914bda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "253e1687",
   "metadata": {},
   "source": [
    "c) Compute the standard deviation of the array. (Hint: this is a built-in attribute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abdba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dfc8a",
   "metadata": {},
   "source": [
    "d) Compute the 40% percentile of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb5e4f",
   "metadata": {},
   "source": [
    "e) Convert the elements to type `int`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc43ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f131681",
   "metadata": {},
   "source": [
    "## Section 3: Axis Operations\n",
    "\n",
    "### Built-in operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "## Generate arbitrary matrix.\n",
    "X = np.linspace(0,5,16).reshape(4,4).round(2)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d42e9",
   "metadata": {},
   "source": [
    "Unless otherwise specified, built-in operations will be applied element-wise (e.g. round) or across the entire array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe327da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6016911",
   "metadata": {},
   "source": [
    "However, we can modify along which dimension an operation is applied using the `axis` flag. Below we sum across the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum across the first axis.\n",
    "print( X.sum(axis=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a5615",
   "metadata": {},
   "source": [
    "Now we sum across the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum across the second axis.\n",
    "print( X.sum(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea6335",
   "metadata": {},
   "source": [
    "## Section 4: Manipulating Arrays \n",
    "\n",
    "### Shaping Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac93c4d",
   "metadata": {},
   "source": [
    "Importantly, all NumPy arrays and matrices have a `reshape` attribute allowing for transforming matrices into different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make new array.\n",
    "x = np.arange(24)\n",
    "\n",
    "## Reshape array.\n",
    "X = x.reshape(24,1);      # col vector\n",
    "print(X)\n",
    "X = x.reshape(1,24);      # row vector\n",
    "X = x.reshape(6,4);       # 2d array\n",
    "X = x.reshape(4,3,2);     # 3d array\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56fd23",
   "metadata": {},
   "source": [
    "One nice feature of NumPy is that it allows for intelligent reshaping. If you specify `-1`, it will determine the size of a remaining dimension based on all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(3,-1,2)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676f01d",
   "metadata": {},
   "source": [
    "In addition to `reshape`, there are a handful of other functions available for manipulating the dimensions of an array.\n",
    "\n",
    "Transpose, `T`, will flip a matrix along its diagonal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c01536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9bc0d",
   "metadata": {},
   "source": [
    "`swapaxes` allows you to reorder two axes of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b619f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X.swapaxes(0,1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745f595",
   "metadata": {},
   "source": [
    "`rollaxis` allows you to shift all axes of an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31972cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rollaxis(X,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c3506",
   "metadata": {},
   "source": [
    "`flatten` allows you to compress an N-d array to a 1-d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.flatten().shape\n",
    "X.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865fa69",
   "metadata": {},
   "source": [
    "### Joining Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc22a36",
   "metadata": {},
   "source": [
    "Assuming they have similar shapes & dtypes, NumPy arrays are easily joined. In general, the syntax is to pass a list of arrays to a joining function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90955f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize array.\n",
    "x = np.arange(10).reshape(5,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e44489",
   "metadata": {},
   "source": [
    "The simplest (silliest) merging approach is to use `np.array` to concatenate two arrays along the first axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a92eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join arrays.\n",
    "X = np.array([x,x])\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa8bc6",
   "metadata": {},
   "source": [
    "There are other joining functions, differing in how (along which axis) they merge two arrays. Some examples are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join along first axis.\n",
    "X = np.concatenate([x,x])\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join along rows (same as vstack).\n",
    "X = np.row_stack([x,x])\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d722bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join along columns (same as hstack).\n",
    "X = np.column_stack([x,x])\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join along specified axis.\n",
    "X = np.concatenate([x,x], axis=1)\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join along new axis.\n",
    "X = np.stack([x,x], axis=0)\n",
    "print(X)\n",
    "print('shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51bc07",
   "metadata": {},
   "source": [
    "### Mini-exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c108a",
   "metadata": {},
   "source": [
    "a) Using a `np.random` function of your choice, make a new array *A* of shape [2,7,4]. Then complete the following steps:\n",
    "- Make a copy of *A*. Store the copy in a new variable *B*.\n",
    "- Swap the first and third axes of *B*.\n",
    "- Flatten *B* into a 1-d array.\n",
    "- Reshape *B* back into the original dimensions of *A*.\n",
    "\n",
    "Now compare A and B. Are they in the same order? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931538b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0a0a4ea",
   "metadata": {},
   "source": [
    "b) Beginning below with *x*, a random [4,1] array, use various joining functions above until you have *X*, a new matrix of shape [12,3]. The order of the elements of *X* don't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f296341",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(size=(4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8ca5b",
   "metadata": {},
   "source": [
    "c) *Y* is a new random variable of shape [1,12,7,3]. Reshape *Y* until you can subtract *X* from it. In other words, reshape this new variable until you can execute: ```Y - X```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3663370",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.normal(size=(1,12,7,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb8bb6",
   "metadata": {},
   "source": [
    "## Section 5: Indexing, Masking, and Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a352b0e",
   "metadata": {},
   "source": [
    "NumPy supports a great many ways of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "## Construct an arbitrary matrix.\n",
    "X = np.random.randint(0, 10, (6,6))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17061922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access particular rows.\n",
    "X[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e460f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access particular columns.\n",
    "X[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access particular rows/columns.\n",
    "X[:5,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf97163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access using lists of indexes.\n",
    "X[[1,3,5],[5,1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad039ff6",
   "metadata": {},
   "source": [
    "Far more useful is indexing with boolean arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return all elements of matrix that meet criterion.\n",
    "X[X > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return all rows that begin with particular integer.\n",
    "X[X[:,0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return all columns whose sum is greater than 40.\n",
    "X[:,X.sum(axis=0) > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e2c56",
   "metadata": {},
   "source": [
    "For larger matrices, we can use the ellipsis as a shorthand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.randint(0,9,(5,5,5,5))\n",
    "Y[0,...,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06ccc2",
   "metadata": {},
   "source": [
    "We can update NumPy arrays in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6212e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update first element.\n",
    "X[0,0] = 55\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update full row.\n",
    "X[3,:] = 66\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fad15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update multiple columns.\n",
    "X[:,-2:] = 77\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923c045",
   "metadata": {},
   "source": [
    "This also allows for convenient masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X==5] = 88\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d0d54",
   "metadata": {},
   "source": [
    "For a complete list of convenient routines, see the [NumPy indexing documentation](https://docs.scipy.org/doc/numpy/user/basics.indexing.html#).\n",
    "\n",
    "`np.where` will also return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "## Construct an arbitrary array.\n",
    "X = np.random.randint(0, 10, (5,3))\n",
    "\n",
    "print(X)\n",
    "print(np.where(X > 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33f1e5",
   "metadata": {},
   "source": [
    "What if we want to find elements that match multiple criteria?\n",
    "\n",
    "The `logical_and` function allows us to find elements where two conditions are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ea398",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and(X > 5, X % 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623ada9",
   "metadata": {},
   "source": [
    "The syntax for two or more conjuctive arguments is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X > 5) & (X % 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd91fa3",
   "metadata": {},
   "source": [
    "Similarly, `logical_or` allows us to find elements where one of two conditions are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[np.logical_or(X < 2, X > 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de980d",
   "metadata": {},
   "source": [
    "The syntax for two or more disjunctive arguments is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42511f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X < 2) | (X > 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f076f32",
   "metadata": {},
   "source": [
    "NumPy includes a number of very helpful functions that allow you to apply a Python function conveniently along parts of an array without Python `for` loops (np.apply_along_axis, np.apply_over_axes). We will illustrate with a simple example of standard-scoring (z-scoring) a matrix.\n",
    "\n",
    "`np.where()` is another function that facilitates masking or selection based on satisfaction of a boolean condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the standard score (z-score) function.\n",
    "def zscore(arr): \n",
    "    return (arr - arr.mean()) / arr.std()\n",
    "\n",
    "## Define a simple matrix.\n",
    "mat = np.arange(12).reshape(2,6)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff69d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "zmat = np.apply_along_axis(zscore, axis=1, arr=mat).round(2)\n",
    "print(zmat)\n",
    "print(zscore(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d100af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumPy includes a number of very helpful functions that allow you to apply a Python function conveniently along parts of an array without Python `for` loops (np.apply_along_axis, np.apply_over_axes). We will illustrate with a simple example of standard-scoring (z-scoring) a matrix.\n",
    "\n",
    "`np.where()` is another function that facilitates masking or selection based on satisfaction of a boolean condition.\n",
    "\n",
    "## Define the standard score (z-score) function.\n",
    "def zscore(arr): \n",
    "    return (arr - arr.mean()) / arr.std()\n",
    "\n",
    "## Define a simple matrix.\n",
    "mat = np.arange(12).reshape(2,6)\n",
    "print(mat)\n",
    "\n",
    "zmat = np.apply_along_axis(zscore, axis=1, arr=mat).round(2)\n",
    "print(zmat)\n",
    "print(zscore(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354eef4",
   "metadata": {},
   "source": [
    "## Section 6: Linear algebra basics in NumPy\n",
    "\n",
    "This section is meant to prepare you for the rest of bootcamp. Here are some basic definitions and pieces of syntax that will form the building blocks for topics to come.\n",
    "\n",
    "The foundation of linear algebra is the **vector**, say vector $x$. That vector can be represented as an array in np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e56ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.random(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56971aa2",
   "metadata": {},
   "source": [
    "The length of a vector is called its **norm**.\n",
    "\n",
    "Formally (but don't worry about this) a norm is a function p: V → R s.t. V is a Vector Space, with the following properties: \n",
    "- For all a ∈ F and all u, v ∈ V, p(av) = |a| p(v), (positive homogeneity or positive scalability). \n",
    "- p(u + v) ≤ p(u) + p(v) (triangle inequality or subadditivity).\n",
    "- If p(v) = 0 then v is the zero vector (separates points).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c30737",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm=np.linalg.norm(x)\n",
    "x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ffefc",
   "metadata": {},
   "source": [
    "A **unit vector** is a vector with magnitude 1; every vector other than a 0 vector can be scaled to unit length. How so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a unit vector in the same direction as x\n",
    "x\n",
    "x_unit=x/np.linalg.norm(x)\n",
    "np.linalg.norm(x_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48042f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.array([0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee4f11",
   "metadata": {},
   "source": [
    "The dot product between vectors $x$ and $z$ is \n",
    "\\begin{align}\n",
    "x \\cdot z &= \\sum_{i=1}^m x_iz_i \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x@z) # native syntax\n",
    "print(np.dot(x,z)) # numpy syntax \n",
    "print(sum(x*z)) # confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d368a6",
   "metadata": {},
   "source": [
    "The same operation can be made on **matrices**, where the elements of each row of the first matrix are multiplied by the corresponding column of the second. This operation is only possible when the number of rows in the first is the same as the number of columns in the second matrix. This operation is also known as the **inner product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57792d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked=np.stack([x]*3)\n",
    "z_stacked=np.stack([z]*4)\n",
    "z_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66724659",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked, z_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1b2ab",
   "metadata": {},
   "source": [
    "Which dimensions of x_stacked and z_stacked agree? We can rotate one of them so that the number of rows agrees with the number of colmns of the other. The rotation is known as the **transpose**, where the matrix is flipped over its diagonals (columns become rows, rows become columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2ea01",
   "metadata": {},
   "source": [
    "What will happen below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77defa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked @ z_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcec8e4",
   "metadata": {},
   "source": [
    "What about here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked.T @ z_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e26eb",
   "metadata": {},
   "source": [
    "And here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stacked @ z_stacked.T\n",
    "x_stacked.shape,z_stacked.T.shape\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077d7af",
   "metadata": {},
   "source": [
    "## Section 7: Introduction to Pandas\n",
    "\n",
    "While Numpy is designed to do fast vectorized calculations with little dependency on external packages. But suppose you have (as in common in research) tabular data consisting of a mix of different types. Basic Numpy is not equipped to handle this in a nice user-friendly\n",
    "\n",
    "What you really want is a spreadsheet, but ideally one that can live inside Python and that also allows fast math as Numpy does.\n",
    "\n",
    "That, in essence, is what Pandas is -- a Python-text-command-driven version of Excel, but more flexible and powerful, with Numpy arrays undergirding the whole thing. \n",
    "\n",
    "Pandas introduces two core data structures -- the Pandas Series and the Pandas DataFrame -- that, while built on top of Numpy arrays, offer some extra functionality that arrays just don't have out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324386b0",
   "metadata": {},
   "source": [
    "## Pandas DataFrames\n",
    "\n",
    "The DataFrame is the core dta analysis object of Pandas. It is very similar to the DataFrame in R. It's essentially a bunch of Series objects glued together into columns, all of which share a common set of indexes.  Unlike a 2D Numpy array, the dtypes of the constituent Series objects can all be different (but *within* a Series, the dtype must be uniform, since that's really a 1D array under the hood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51634791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "DataFrame?\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a628c2",
   "metadata": {},
   "source": [
    "### Generating DataFrames\n",
    "\n",
    "A DataFrame can be generated directly from:\n",
    "\n",
    "* A dict of arrays/lists/Series/other dicts\n",
    "* A 2D array\n",
    "* The Numpy \"structured array\" we mentioned up top (beyond our scope)\n",
    "* A single Series (if you want a single-column DataFrame)\n",
    "* Another DataFrame\n",
    "* A file of data (e.g. a csv)\n",
    "\n",
    "Indexes are specified with the `index` keyword (these will label rows), and column labels with the `columns` keyword.\n",
    "\n",
    "Let's see how some of these work (it works very similarly to how Series are generated)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45830baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary of array-like stuff\n",
    "mydict = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "          'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "# The dictionary keys become columns.\n",
    "print(pd.DataFrame(mydict))\n",
    "\n",
    "# You can override this with the \"columns\" keyword, but watch out!  -- unless your specified columns overlap with the\n",
    "# keys, you will get an empty DataFrame\n",
    "print(\"\\nThis will be empty...\\n\")\n",
    "print(pd.DataFrame(mydict, columns=['width','length']))\n",
    "print(\"\\n...but this will not be\\n\")\n",
    "print(pd.DataFrame(mydict, columns=['two', 'width']))\n",
    "print(\"\\n...and neither will this\\n\")\n",
    "print(pd.DataFrame(mydict, columns=['two', 'width', 'one']))\n",
    "\n",
    "# Notice how the index & column behavior with NaN works analogously to what we saw for Series.\n",
    "\n",
    "# We can add an \"index\" keyword for the whole DataFrame, and that will supersede the individual Series ones,\n",
    "# with the same sort of NaN behavior\n",
    "\n",
    "print(pd.DataFrame(mydict, index=['b', 'd', 'a']))\n",
    "print(\"\\nand\\n\")\n",
    "print(pd.DataFrame(mydict, index=['b', 'd', 'a'], columns=['two', 'width', 'one']))\n",
    "\n",
    "print(\"\\nand\\n\")\n",
    "print(pd.DataFrame(mydict, index=['b', 'd', 'a'], columns=['length', 'width']))\n",
    "\n",
    "# Getting how this works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da458652",
   "metadata": {},
   "source": [
    "Most importantly, DataFrames can be generated by reading in CSV/Excel files. Here we read in a CSV of choice behavior data from [Tom et al. (2007)](https://www.ncbi.nlm.nih.gov/pubmed/17255512) [data available [here](https://openneuro.org/datasets/ds000005/versions/00001)]. Briefly, this dataset is comprised of the behavior gathered from 16 participants who completed a gambling task (three sessions each).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from CSV.\n",
    "data = pd.read_csv('gambles.csv')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.size)\n",
    "print(data.index)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2c17f",
   "metadata": {},
   "source": [
    "DataFrames support all of the core operations that NumPy arrays do. However, DataFrames do so in an organized fashion for easy describing of data.  Try running each of the commands below (which work just as they do for Numpy arrays):\n",
    "\n",
    "```python\n",
    "data.round();\n",
    "data.sum();\n",
    "data.max();\n",
    "data.min();\n",
    "data.mean();\n",
    "data.std();\n",
    "data.median()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231734e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add column denoting rows with missing data.\n",
    "data['Missing'] = data.Choice.isnull().astype(int)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88aa194",
   "metadata": {},
   "source": [
    "Similarly, it is easy to drop rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check original shape.\n",
    "print(f'Original shape: {data.shape}')\n",
    "\n",
    "## Drop missing data.\n",
    "data = data.dropna()\n",
    "\n",
    "## Check new shape.\n",
    "print(f'Original shape: {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad27da7",
   "metadata": {},
   "source": [
    "Particular columns can also be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop missing data column.\n",
    "data = data.drop(['Missing'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94910199",
   "metadata": {},
   "source": [
    "DataFrames are easily converted back to NumPy arrays and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c48f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To NumPy array.\n",
    "arr = data.values\n",
    "\n",
    "## To dictionary.\n",
    "dd = data.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29781a2d",
   "metadata": {},
   "source": [
    "DataFrames can also be easily written to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c1f61",
   "metadata": {},
   "source": [
    "## Section 8: Visualization w/ Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "## NOTE: The second line is a bit of notebook magic! \n",
    "## It's a jupyter-notebook shortcut that makes all\n",
    "## plots be displayed at the bottom of a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27324cb4",
   "metadata": {},
   "source": [
    "### Basic Example\n",
    "Lineplots are the most intuitive Matplotlib plot, requiring at the minimum only the x- and y-datapoints. Many embellishments can be added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize canvas.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "\n",
    "## Define sigmoid function.\n",
    "def inv_logit(arr):\n",
    "    return 1. / (1 + np.exp(-arr))\n",
    "\n",
    "## Simulate data.\n",
    "x = np.linspace(-5,5,101)\n",
    "\n",
    "\n",
    "## Plot lines.\n",
    "for b in [0.5,1.0,2.0]:\n",
    "    y = inv_logit(x * b)\n",
    "    ax.plot(x, y, lw=2.5, label=r'$y = logit^{-1}( \\ %0.1f \\cdot x \\ )$' %b)\n",
    "\n",
    "## Add details.\n",
    "ax.set(xlim=(x.min(), x.max()), xlabel='X', ylim=(0), ylabel='Y', title='Example Lineplot')\n",
    "ax.legend(loc=2, frameon=False, fontsize=14)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea59de8",
   "metadata": {},
   "source": [
    "The Seaborn statistical data visualization library was created to be the equivalent of ggplot2 for python. In other words, it is designed to rapidly turn around publication-ready plots from Pandas DataFrames with as minimal code as necessary. The [documention](https://seaborn.pydata.org/) is full of great examples that should be checked out. We will go through a few examples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ec285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27260dc2",
   "metadata": {},
   "source": [
    "### Style and Context\n",
    "One of the great things about Seaborn is setting defaults. The defaults set a variety of parameters (e.g. colors, fonts, font sizes, etc.) that result in little tweaking of figures down the line. We introduce those two functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set_style sets the aesthetic style of the plots. This most dramatically \n",
    "## affects the background of plots and the presence (or absence) of gridlines.\n",
    "sns.set_style('white')      # {white, whitegrid, dark, darkgrid}\n",
    "\n",
    "## set_context sets the context parameters, affecting the size of labels,\n",
    "## lines, and other elements of the plot.\n",
    "sns.set_context('notebook', font_scale=1.5) # {notebook, paper, talk, poster}\n",
    "\n",
    "## Text plot.\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(np.arange(10), np.arange(10));\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3de15",
   "metadata": {},
   "source": [
    "### Barplots\n",
    "Let's first start by recreating the barplot from earlier (i.e. average response within subjects). As can be seen, substantially fewer lines of code are necessary. Moreover, 95% CIs are computed via bootstrap resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize figure.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "\n",
    "## Plot barplot.\n",
    "sns.barplot('Subject', 'Choice', data=data, color='#377eb8', ax=ax)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74331a94",
   "metadata": {},
   "source": [
    "### Pointplots / Lineplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b89a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize figure.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "\n",
    "## GroupBy subject/gain.\n",
    "gb = data.groupby(['Subject','Gain']).Choice.mean().reset_index()\n",
    "\n",
    "## Plot pointplot.\n",
    "sns.pointplot('Gain', 'Choice', data=gb, ax=ax)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize figure.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "\n",
    "## GroupBy subject/gain.\n",
    "gb = data.groupby(['Subject','Gain']).Choice.mean().reset_index()\n",
    "\n",
    "## Plot regression.\n",
    "sns.regplot('Gain', 'Choice', data=gb, ax=ax)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55434027",
   "metadata": {},
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize figure.\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "\n",
    "## Plot distribution.\n",
    "sns.distplot(data.RT, ax=ax)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0bdb8",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ff847",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize figure.\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,4))\n",
    "\n",
    "## Compute pivot table.\n",
    "table = data.pivot_table(index='Gain', columns='Loss', values='Choice')\n",
    "table\n",
    "## Plot heatmap.\n",
    "sns.heatmap(table.T, vmin=0, vmax=1, center=0.5, ax=ax)\n",
    "ax.invert_yaxis()\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdab809",
   "metadata": {},
   "source": [
    "### FacetGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b260acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize canvas.\n",
    "g = sns.FacetGrid(data, col='Subject', col_wrap=4, sharex=True, sharey=False)\n",
    "\n",
    "## Plot histograms.\n",
    "g.map(sns.distplot, 'RT', bins=np.linspace(0,3,25), kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4ce71",
   "metadata": {},
   "source": [
    "# Section 3: Introduction to Statistics (SciPy + Statsmodels)\n",
    "\n",
    "## SciPy Statistics Module\n",
    "SciPy introduces a series of special modules for different computations, including: integration, optimization, signal and image processing, and statistics. The [SciPy documentation](https://docs.scipy.org/doc/scipy/reference/) details the many powerful tools the package introduces.\n",
    "\n",
    "The [SciPy stats module](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html) (scipy.stats) introduces a number of helpful functions, including:\n",
    "* Statistical distributions (e.g. normal, student-t, inv-normal, gamma, beta, binomal..., [full list](https://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* Measures of distributional shape (e.g. kurtosis, skew, QQ-plots, KS-test)\n",
    "* Basic statistical tests (e.g. linear correlation, nonparametric correlation, t-tests, one-way ANOVA, Chi-Square)\n",
    "\n",
    "The SciPy package can be especially helpful when the user needs to compute quick statistics without necessarily needing to implement even simple models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264e129",
   "metadata": {},
   "source": [
    "### Basic Statistics\n",
    "SciPy also has implemented several basic statistical functions for quickly computing statistics:\n",
    "* Correlations: Pearson correlation (``pearsonr``), Spearman correlation (``spearmanr``), Kendall Tau (``kendalltau``)\n",
    "* T-tests: one-sample t-test (``ttest_1samp``), two-sample t-test (``ttest_ind``), dependent sample t-test (``ttest_rel``)\n",
    "* ANOVA: One-way ANOVA (``f_oneway``)\n",
    "* Chi-square (``chisquare``, ``chi2_contingency``)\n",
    "\n",
    "We will quickly highlight a few of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, ttest_ind\n",
    "np.random.seed(47404)\n",
    "\n",
    "## Simulate data from multivariate normal distribution.\n",
    "## The two variables will be of different mean and r=0.4 correlated.\n",
    "\n",
    "## Define means / covariances.\n",
    "mu = [0,2]\n",
    "cov = [[1.0, 0.4],\n",
    "       [0.4, 1.0]]\n",
    "\n",
    "## Randomly sample 50 observations.\n",
    "x, y = np.random.multivariate_normal(mu, cov, 50).T\n",
    "\n",
    "## Compute correlation of pairs: (1,2), (1,3)\n",
    "print('Pearson: r = %0.3f, p = %0.3f' %pearsonr(x, y))\n",
    "\n",
    "## Compute independent t-tests\n",
    "print('Independent t-test: t = %0.3f, p = %0.20f' %ttest_ind(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47f29d",
   "metadata": {},
   "source": [
    "## Statsmodels\n",
    "Statsmodels is the prominent statistical models package in the scientific python distribution. Statsmodels provides functionality for linear regression, generalized linear models, limited dependent variable models, ARMA and VAR models. The [Statsmodels documentation](http://www.statsmodels.org/stable/index.html) provides a full list of models and functions implemented. It draws its inspiration from the most popular R statistics packages (e.g. lme4) and uses the same statistical modeling syntax as R (e.g. \"y ~ x\"). As we will see, the package is still new and relatively limited as of the time of writing. Though the most basic models are implemented, more complex yet standard models (e.g. mixed-effects logistic regression) are not yet implemented. \n",
    "\n",
    "\n",
    "If you are familiar with R-styled formulas for regression, then Statsmodels + Pandas is a very powerful combo of packages for data analysis in python. We will cover only a few select examples, but know that many models are already implemented (e.g. OLS, GLM, GEE, WLS). Many more well-documented tutorials can be found [here](http://www.statsmodels.org/stable/examples/index.html#notebook-examples) and [here](https://github.com/statsmodels/statsmodels/wiki/Examples). \n",
    "\n",
    "### Linear Regression (OLS)\n",
    "Below is a basic ordinary least squares (OLS) linear regression model measuring the relationship of subjective likelihood-of-take (respnum) against gain and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "## Define formula.\n",
    "formula = 'RT ~ Gain + Loss'\n",
    "\n",
    "## Define model.\n",
    "model = OLS.from_formula(formula, data=data)\n",
    "\n",
    "## Fit model.\n",
    "result = model.fit()\n",
    "\n",
    "## Print summary.\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebb3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
